{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Import Library\n",
    "import pandas as pd\n",
    "import re\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import os\n",
    "import openai\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "from langchain_experimental.agents.agent_toolkits import create_csv_agent\n",
    "import glob\n",
    "import json\n",
    "import ast\n",
    "from langchain.agents import create_sql_agent\n",
    "from langchain.agents.agent_toolkits import SQLDatabaseToolkit\n",
    "from langchain.sql_database import SQLDatabase\n",
    "from langchain.llms.openai import OpenAI\n",
    "from langchain.agents.agent_types import AgentType\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "import spacy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "## load the API key\n",
    "_ = load_dotenv(find_dotenv()) # read local .env file\n",
    "openai.api_key  = os.getenv('OPENAI_API_KEY')\n",
    "\n",
    "## Pass the dataset to agent to get a summary about the dataset\n",
    "def info_about_dataset(db_id):\n",
    "    csv_files = glob.glob(f\"{db_id}/*.csv\")\n",
    "    csv_file_path = csv_files[0]\n",
    "    df = pd.read_csv(csv_file_path)\n",
    "    df_columns = df.columns\n",
    "    df_columns = df_columns.tolist()\n",
    "\n",
    "    prompt = \"\"\"Given a csv file. I want to understand the dataset and provide a brief and consise summary of the data in atleast 100 words\"\"\"\n",
    "    agent = create_csv_agent(\n",
    "        OpenAI(temperature=0.5, max_tokens=1500), csv_file_path, verbose=False)\n",
    "\n",
    "    r_summary = agent.run(prompt)\n",
    "    print(\"Dataset summary given by agent---------->\", r_summary)\n",
    "    return r_summary,df_columns\n",
    "\n",
    "## Generate question with Chatgpt API\n",
    "def question_generator(r_summary, df_columns):\n",
    "    model =\"gpt-3.5-turbo-0613\"\n",
    "\n",
    "    prstr1 = \"Create maximum number of UNIQUE suggestion questions that you can generate from the information provided by \" + r_summary + \"having columns \" + str(df_columns) + \"make questions short, concise and compact with 3-5 words\"\n",
    "    tmp = \"\"\"\n",
    "    Please meet the following conditions.\n",
    "    ・questions should include all aspects of the dataset\n",
    "    ・does not include any interrogative words and only main keywords of question\n",
    "    ・strictly do not include serial numbers in questions\n",
    "    ・each question is comma seperated\n",
    "     * Make sure that each question should be related to data and should generate data based meaningful responses\n",
    "    \"\"\"\n",
    "    prstr1 += tmp\n",
    "    response = openai.ChatCompletion.create(\n",
    "        model = model,\n",
    "        temperature= 0.5,\n",
    "        messages=[\n",
    "            {\"role\": \"user\", \"content\": prstr1},\n",
    "        ],\n",
    "    )\n",
    "    res1 = response.choices[0][\"message\"][\"content\"].strip()\n",
    "    # res1\n",
    "    output = res1.split(\"\\n\")[1:]\n",
    "    pattern = r'^\\d+\\.\\s'\n",
    "    cleaned_list = [re.sub(pattern, '', item) for item in output]\n",
    "    return cleaned_list\n",
    "\n",
    "## Use cosine similarity to  reommend similar question\n",
    "def Recommendation_question(question_list):\n",
    "    nlp = spacy.load(\"en_core_web_sm\")\n",
    "    questions = question_list\n",
    "    processed_questions = [nlp(question) for question in questions]\n",
    "\n",
    "    similar_questions = {}\n",
    "\n",
    "    for i in range(len(questions)):\n",
    "        question = questions[i]\n",
    "        vector1 = processed_questions[i].vector\n",
    "\n",
    "        similar_questions[i] = {\n",
    "            'main_suggestion': question,\n",
    "            'sub_suggestions': []\n",
    "        }\n",
    "\n",
    "        for j in range(len(questions)):\n",
    "            if i != j:\n",
    "                vector2 = processed_questions[j].vector\n",
    "                similarity = cosine_similarity([vector1], [vector2])[0][0]\n",
    "\n",
    "                if similarity > 0.6:\n",
    "                    similar_questions[i]['sub_suggestions'].append(questions[j])\n",
    "\n",
    "        # Ensure there are at least 3 sub-suggestions\n",
    "        while len(similar_questions[i]['sub_suggestions']) < 3:\n",
    "            dissimilar_questions = [\n",
    "                q for q in questions if q != question and q not in similar_questions[i]['sub_suggestions']\n",
    "            ]\n",
    "            if dissimilar_questions:\n",
    "                similar_questions[i]['sub_suggestions'].append(dissimilar_questions.pop())\n",
    "            else:\n",
    "                break\n",
    "\n",
    "    return similar_questions\n",
    "\n",
    "## Final suggestion and recmmendation function\n",
    "## Work on CSV and DB file\n",
    "## For now recommendation works on only CSV dataset\n",
    "def generate_suggestions(folder_path):\n",
    "    all_files = glob.glob(os.path.join(folder_path, '*'))\n",
    "\n",
    "    if not all_files:\n",
    "        raise FileNotFoundError(f\"No files found in directory: {folder_path}\")\n",
    "\n",
    "    # Initialize variables to store results\n",
    "    results = {}\n",
    "\n",
    "    # Loop through each file in the folder\n",
    "    for file_path in all_files:\n",
    "        # Check if the file is a CSV file\n",
    "        if file_path.lower().endswith('.csv'):\n",
    "            try:\n",
    "                r_summary,df_columns = info_about_dataset(folder_path)\n",
    "                output = question_generator(r_summary, df_columns)\n",
    "                similar_question_list = Recommendation_question(output)\n",
    "                results = {\"question_suggestion\": similar_question_list}\n",
    "            except Exception as e:\n",
    "                print(f\"Error processing CSV file {file_path}: {str(e)}\")\n",
    "                \n",
    "\n",
    "        # Check if the file is a DB file\n",
    "        elif file_path.lower().endswith('.db'):\n",
    "            try:\n",
    "                db = SQLDatabase.from_uri(f\"sqlite:///{file_path}\")\n",
    "                toolkit = SQLDatabaseToolkit(db=db, llm=OpenAI(temperature=0.5))\n",
    "                agent_executor = create_sql_agent(\n",
    "                    llm=ChatOpenAI(temperature=0, model=\"gpt-3.5-turbo-0613\"),\n",
    "                    toolkit=toolkit,\n",
    "                    verbose=False,\n",
    "                    agent_type=AgentType.OPENAI_FUNCTIONS\n",
    "                )\n",
    "                response = agent_executor.run(\"You are provided with database schema,read the complete database and suggest top 10-15 unique questions to ask from this schema. Return the output\")  # Replace with your SQL query\n",
    "                questions = response.split('\\n')[2:]\n",
    "                questions = [q.strip(' 1234567890. ') for q in questions if q.strip()]\n",
    "                similar_question_list = Recommendation_question(questions[:-1])\n",
    "                results = {\"question_suggestion\": similar_question_list}\n",
    "            except Exception as e:\n",
    "                print(f\"Error processing DB file {file_path}: {str(e)}\")\n",
    "\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing CSV file C:\\Users\\DELL LATITUDE E5470\\Desktop\\Suggesations\\Housing.csv: The model `text-davinci-003` has been deprecated, learn more here: https://platform.openai.com/docs/deprecations\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "folder_path = r\"C:\\Users\\DELL LATITUDE E5470\\Desktop\\Suggesations\"\n",
    "generate_suggestions(folder_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
